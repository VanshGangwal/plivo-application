[INTRO]
Hello everyone, my name is Vansh Gangwal. I am a final year student pursuing IDDD in Data Science at IIT Madras. Today, I will be presenting my solution for the PII Named Entity Recognition task on noisy Speech-to-Text data.

[PROBLEM STATEMENT]
The objective was to build a token-level NER model capable of identifying sensitive entities like Credit Cards, Phone Numbers, Emails, and Names from raw, noisy audio transcripts. The key constraints were strict: a p95 latency of under 20 milliseconds on CPU, and a high PII precision of at least 0.80.

[CODE BASE EXPLANATION & DATA STRATEGY]
A critical part of this solution was the Data Generation strategy. Since no training data was provided, I couldn't simply use standard datasets because they don't reflect the chaos of raw speech transcripts.
I built a custom data pipeline using the `Faker` library to generate thousands of realistic PII entities. But the real magic is in the noise injection. I wrote specific logic to simulate Speech-to-Text errors. For example, I converted digits like '123' to words 'one two three', replaced symbols like '@' with 'at' and '.' with 'dot', and stripped away all punctuation and capitalization.
This synthetic dataset effectively forced the model to learn the *context* of PII rather than relying on easy cues like formatting, which is crucial for real-world robustness.
The core logic resides in `src/train.py` for training and `src/predict.py` for inference, where I implemented a BIO-to-span decoder.

[MODEL & TOKENIZER]
For the model, I initially experimented with `distilbert-base-uncased`. While it achieved excellent accuracy, it was too slow, with a p95 latency of around 39 milliseconds. I then tried dynamic quantization, but surprisingly, it increased latency to 59 milliseconds due to CPU overhead on single-batch inference.
My final choice was `prajjwal1/bert-mini`. This is a compact BERT model with only 4 layers and a hidden size of 256, compared to the standard 768. It uses the corresponding BERT tokenizer.

[KEY HYPERPARAMETERS]
I trained this model for 5 epochs with a learning rate of 5e-5 and a batch size of 8. These settings allowed the smaller model to converge effectively on the synthetic dataset without overfitting.

[FINAL RESULTS]
The results were highly successful.
On the development set, the model achieved a PII Precision of 0.949, well above the 0.80 target. The Recall was 0.977, and the F1 score was 0.963.
Most importantly, the latency target was met.

[LATENCY & TRADE-OFFS]
The final p95 latency was 16.89 milliseconds on CPU, comfortably under the 20ms limit.
The trade-off here is clear: by switching to a smaller architecture like `bert-mini`, we sacrificed a tiny bit of theoretical capacity compared to a large model, but we gained a 2x speedup that made the system viable for real-time applications.

[CONCLUSION]
In conclusion, this solution demonstrates that for specific tasks like NER, smaller, specialized models can deliver high accuracy while meeting strict latency requirements. Thank you.
