[INTRO]
Hello everyone, my name is Vansh Gangwal. I am a final year student pursuing IDDD in Data Science at IIT Madras. Today, I will be presenting my solution for the PII Named Entity Recognition task on noisy Speech-to-Text data.

[PROBLEM STATEMENT]
The objective was to build a token-level NER model capable of identifying sensitive entities like Credit Cards, Phone Numbers, Emails, and Names from raw, noisy audio transcripts. The key constraints were strict: a p95 latency of under 20 milliseconds on CPU, and a high PII precision of at least 0.80.

[CODE BASE EXPLANATION]
Let me briefly walk you through the codebase.
I started by creating a robust data generation script using the `Faker` library. Since the input is "noisy" STT, I couldn't just use clean text. My script injects realistic noiseâ€”spelling out numbers like "one two three", replacing dots with the word "dot", and removing punctuation. This ensures the model learns to handle the actual messiness of speech transcripts.
The core logic resides in `src/train.py` for training the model and `src/predict.py` for inference, where I implemented a BIO-to-span decoder to extract the entities.

[MODEL & TOKENIZER]
For the model, I initially experimented with `distilbert-base-uncased`. While it achieved excellent accuracy, it was too slow, with a p95 latency of around 39 milliseconds. I then tried dynamic quantization, but surprisingly, it increased latency to 59 milliseconds due to CPU overhead on single-batch inference.
My final choice was `prajjwal1/bert-mini`. This is a compact BERT model with only 4 layers and a hidden size of 256, compared to the standard 768. It uses the corresponding BERT tokenizer.

[KEY HYPERPARAMETERS]
I trained this model for 5 epochs with a learning rate of 5e-5 and a batch size of 8. These settings allowed the smaller model to converge effectively on the synthetic dataset without overfitting.

[FINAL RESULTS]
The results were highly successful.
On the development set, the model achieved a PII Precision of 0.949, well above the 0.80 target. The Recall was 0.977, and the F1 score was 0.963.
Most importantly, the latency target was met.

[LATENCY & TRADE-OFFS]
The final p95 latency was 16.89 milliseconds on CPU, comfortably under the 20ms limit.
The trade-off here is clear: by switching to a smaller architecture like `bert-mini`, we sacrificed a tiny bit of theoretical capacity compared to a large model, but we gained a 2x speedup that made the system viable for real-time applications.

[CONCLUSION]
In conclusion, this solution demonstrates that for specific tasks like NER, smaller, specialized models can deliver high accuracy while meeting strict latency requirements. Thank you.
